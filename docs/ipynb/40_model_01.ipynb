{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_selection as fs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Build Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1: Load the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (18558, 1803)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n622</th>\n",
       "      <th>n0region</th>\n",
       "      <th>n1region</th>\n",
       "      <th>n2region</th>\n",
       "      <th>n3region</th>\n",
       "      <th>n553</th>\n",
       "      <th>n545</th>\n",
       "      <th>n520</th>\n",
       "      <th>n490</th>\n",
       "      <th>n492</th>\n",
       "      <th>...</th>\n",
       "      <th>OUTCME02</th>\n",
       "      <th>OUTCME03</th>\n",
       "      <th>OUTCME04</th>\n",
       "      <th>OUTCME05</th>\n",
       "      <th>OUTCME06</th>\n",
       "      <th>OUTCMEBM</th>\n",
       "      <th>OUTCME07</th>\n",
       "      <th>OUTCME08</th>\n",
       "      <th>OUTCME09</th>\n",
       "      <th>epileptic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n622  n0region  n1region  n2region  n3region  n553  n545  n520  n490  n492  \\\n",
       "0   2.0       9.0       9.0       9.0       9.0  23.0   4.0   2.0  12.0   5.0   \n",
       "1   1.0       9.0       8.0       8.0       8.0  34.0   4.0   5.0   1.0   4.0   \n",
       "2   2.0       1.0       1.0       1.0       1.0  26.0   4.0  11.0   1.0   4.0   \n",
       "3   2.0      10.0      10.0      10.0      10.0  25.0   4.0   1.0   3.0   6.0   \n",
       "4   2.0       7.0       7.0       7.0       7.0  26.0   4.0   1.0   1.0   4.0   \n",
       "\n",
       "     ...      OUTCME02  OUTCME03  OUTCME04  OUTCME05  OUTCME06  OUTCMEBM  \\\n",
       "0    ...           1.0       1.0       1.0       1.0       1.0       1.0   \n",
       "1    ...           1.0       1.0       1.0       1.0       1.0       1.0   \n",
       "2    ...           1.0       1.0       1.0       1.0       1.0       1.0   \n",
       "3    ...           1.0       1.0       2.0       2.0       2.0       6.0   \n",
       "4    ...           1.0       1.0       3.0       2.0       3.0       6.0   \n",
       "\n",
       "   OUTCME07  OUTCME08  OUTCME09  epileptic  \n",
       "0       1.0       1.0       1.0          0  \n",
       "1       1.0       1.0       1.0          0  \n",
       "2       2.0       2.0       3.0          0  \n",
       "3       6.0       6.0       6.0          0  \n",
       "4       6.0       4.0       6.0          1  \n",
       "\n",
       "[5 rows x 1803 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the clean data\n",
    "ncds_data_no_indicators = pd.read_csv('datasets/ncds_data_no_indicators.csv', delimiter=',', low_memory=False)\n",
    "# Print shapes\n",
    "print \"Shape of data:\", ncds_data_no_indicators.shape\n",
    "ncds_data_no_indicators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 1.2: Split data into train and test\n",
    "Split our dataset into train and test and analyze the splits. We can explore and verify the matrix of classes to check if our data is balanced. If the class is Imbalanced we will need to do any of the following:\n",
    "1. Over sample\n",
    "2. Under sample\n",
    "3. Over weight\n",
    "4. Adjust class weights in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (11134, 1802)\n",
      "Test data:  (7424, 1802)\n",
      "Train class 0: 10113, train class 1: 1021\n",
      "Test class 0: 6735, test class 1: 689\n"
     ]
    }
   ],
   "source": [
    "x = ncds_data_no_indicators.values[:, :-1]\n",
    "y = ncds_data_no_indicators.values[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#Print some useful info for our test, train sets\n",
    "print 'Train data: ', x_train.shape\n",
    "print 'Test data: ', x_test.shape\n",
    "print 'Train class 0: {}, train class 1: {}'.format(len(y_train[y_train == 0]), len(y_train[y_train == 1]))\n",
    "print 'Test class 0: {}, test class 1: {}'.format(len(y_test[y_test == 0]), len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3: Feature Selection\n",
    "\n",
    "From the merged datasets we can see we have over 1800 features. Going through the 1800 would be a very time consuming task so let us apply some algorithims to find the best features that we can use to build the model. In our exploration phase we did use PCA to find a subset of components but chose not to use those components in our base models. The exploration phase can be seen [here](20_exploratory_data_analysis_02.ipynb). However we may chose to use PCA during model tuning and evaluating model performance phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['n400' 'n1827' 'n604' 'n35' 'n39' 'n1400' 'n825' 'n2598' 'n1896' 'n1897'\n",
      " 'n1898' 'n2009' 'n2010' 'OUTCME01' 'OUTCME02']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/pandas/indexes/base.py:1275: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 1803 but corresponding boolean dimension is 1802\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "# Best features\n",
    "num_of_features = 15\n",
    "features = fs.SelectKBest(fs.f_regression, k=num_of_features) #k is number of features.\n",
    "features.fit(x_train, y_train)\n",
    "\n",
    "selected_features = features.get_support()\n",
    "print \"Selected Features:\"\n",
    "selected_features_columns =  ncds_data_no_indicators.columns[selected_features].values\n",
    "print selected_features_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4: Build various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for computing the accuracy a given model on the entire test set,\n",
    "# the accuracy on class 0 in the test set\n",
    "# and the accuracy on class 1\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (11134, 15)\n",
      "Test data:  (7424, 15)\n",
      "Train class 0: 10113, train class 1: 1021\n",
      "Test class 0: 6735, test class 1: 689\n"
     ]
    }
   ],
   "source": [
    "# Split data for selected features only\n",
    "x = ncds_data_no_indicators[selected_features_columns].values[:,:]\n",
    "y = ncds_data_no_indicators.values[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#Print some useful info for our test, train sets\n",
    "print 'Train data: ', x_train.shape\n",
    "print 'Test data: ', x_test.shape\n",
    "print 'Train class 0: {}, train class 1: {}'.format(len(y_train[y_train == 0]), len(y_train[y_train == 1]))\n",
    "print 'Test class 0: {}, test class 1: {}'.format(len(y_test[y_test == 0]), len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (Unweighted):\n",
      "overall accuracy       0.908675\n",
      "accuracy on class 0    0.997327\n",
      "accuracy on class 1    0.042090\n",
      "dtype: float64\n",
      "Logistic regression (Weighted):\n",
      "overall accuracy       0.648303\n",
      "accuracy on class 0    0.657313\n",
      "accuracy on class 1    0.560232\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train)\n",
    "unweighted_log_scores = score(unweighted_logistic, x_test, y_test)\n",
    "\n",
    "# Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train)\n",
    "weighted_log_scores = score(weighted_logistic, x_test, y_test)\n",
    "\n",
    "print \"Logistic regression (Unweighted):\"\n",
    "print unweighted_log_scores\n",
    "print \"Logistic regression (Weighted):\"\n",
    "print weighted_log_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "overall accuracy       0.906115\n",
      "accuracy on class 0    0.990943\n",
      "accuracy on class 1    0.076923\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_scores = score(lda, x_test, y_test)\n",
    "\n",
    "print \"LDA:\"\n",
    "print lda_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA:\n",
      "overall accuracy       0.847791\n",
      "accuracy on class 0    0.911210\n",
      "accuracy on class 1    0.227866\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train)\n",
    "qda_scores = score(qda, x_test, y_test)\n",
    "\n",
    "print \"QDA:\"\n",
    "print qda_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees:\n",
      "overall accuracy       0.896013\n",
      "accuracy on class 0    0.974759\n",
      "accuracy on class 1    0.126270\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees\n",
    "tree = DecisionTree()\n",
    "tree.fit(x_train, y_train)\n",
    "tree_scores = score(tree, x_test, y_test)\n",
    "\n",
    "print \"Decision Trees:\"\n",
    "print tree_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "overall accuracy       0.791891\n",
      "accuracy on class 0    0.843207\n",
      "accuracy on class 1    0.290276\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForest(class_weight='balanced')\n",
    "rf.fit(x_train, y_train)\n",
    "rf_scores = score(rf, x_test, y_test)\n",
    "\n",
    "print \"Random Forest:\"\n",
    "print rf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "overall accuracy       0.760776\n",
      "accuracy on class 0    0.794655\n",
      "accuracy on class 1    0.429608\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "svc = SVC(probability=True,class_weight='balanced')\n",
    "svc.fit(x_train, y_train)\n",
    "svc_scores = score(svc, x_test, y_test)\n",
    "\n",
    "print \"SVC:\"\n",
    "print svc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "overall accuracy       0.905711\n",
      "accuracy on class 0    0.990794\n",
      "accuracy on class 1    0.074020\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNN()\n",
    "knn.fit(x_train, y_train)\n",
    "knn_scores = score(knn, x_test, y_test)\n",
    "\n",
    "print \"KNN:\"\n",
    "print knn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Overall Score Dataframe\n",
    "performance_metric = pd.DataFrame({'Unweighted Logistic': unweighted_log_scores,\n",
    "                         'Weighted Logistic': weighted_log_scores,\n",
    "                         'LDA': lda_scores,\n",
    "                         'QDA': qda_scores,\n",
    "                        'KNN': knn_scores,\n",
    "                         'Tree': tree_scores,\n",
    "                         'RF': rf_scores,'SVC':svc_scores})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4: Define Performance Metric\n",
    "\n",
    "Our performance metric will be to build a model whos results are better than the base models we have built so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Performance Metric is to get a better score the following:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Unweighted Logistic</th>\n",
       "      <th>Weighted Logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.905711</td>\n",
       "      <td>0.906115</td>\n",
       "      <td>0.847791</td>\n",
       "      <td>0.791891</td>\n",
       "      <td>0.760776</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.908675</td>\n",
       "      <td>0.648303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.990794</td>\n",
       "      <td>0.990943</td>\n",
       "      <td>0.911210</td>\n",
       "      <td>0.843207</td>\n",
       "      <td>0.794655</td>\n",
       "      <td>0.974759</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.657313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.074020</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.227866</td>\n",
       "      <td>0.290276</td>\n",
       "      <td>0.429608</td>\n",
       "      <td>0.126270</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.560232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          KNN       LDA       QDA        RF       SVC  \\\n",
       "overall accuracy     0.905711  0.906115  0.847791  0.791891  0.760776   \n",
       "accuracy on class 0  0.990794  0.990943  0.911210  0.843207  0.794655   \n",
       "accuracy on class 1  0.074020  0.076923  0.227866  0.290276  0.429608   \n",
       "\n",
       "                         Tree  Unweighted Logistic  Weighted Logistic  \n",
       "overall accuracy     0.896013             0.908675           0.648303  \n",
       "accuracy on class 0  0.974759             0.997327           0.657313  \n",
       "accuracy on class 1  0.126270             0.042090           0.560232  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Our Performance Metric is to get a better score the following:\"\n",
    "performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Write the Performance Metric dataframe to a csv file\n",
    "performance_metric.to_csv('datasets/performance_metric.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
