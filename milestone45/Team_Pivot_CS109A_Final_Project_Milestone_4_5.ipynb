{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Project Milestone 4/5\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_selection as fs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Explore and Clean Data\n",
    "\n",
    "First task will be to read, explore, and clean the data. Our first version of the data exploration can be found [here](ExploreData.ipynb). There was a lot of exploratory and debugging code, so we branched off ot this notebook with the findings we thought would be appropriate for this milestone of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (18558, 1765)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncdsid</th>\n",
       "      <th>n622</th>\n",
       "      <th>n0region</th>\n",
       "      <th>n1region</th>\n",
       "      <th>n2region</th>\n",
       "      <th>n3region</th>\n",
       "      <th>n553</th>\n",
       "      <th>n545</th>\n",
       "      <th>n520</th>\n",
       "      <th>n490</th>\n",
       "      <th>...</th>\n",
       "      <th>n1849</th>\n",
       "      <th>dvht07</th>\n",
       "      <th>dvht11</th>\n",
       "      <th>dvht16</th>\n",
       "      <th>dvrwt07</th>\n",
       "      <th>dvrwt11</th>\n",
       "      <th>dvrwt16</th>\n",
       "      <th>dvwt07</th>\n",
       "      <th>dvwt11</th>\n",
       "      <th>dvwt16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10001N</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.21899986267032</td>\n",
       "      <td>1.47299957275415</td>\n",
       "      <td>1.59999942779607</td>\n",
       "      <td>110.347991943347</td>\n",
       "      <td>98.1929931640604</td>\n",
       "      <td>105.055999755876</td>\n",
       "      <td>25.8549957275385</td>\n",
       "      <td>37.6489868164152</td>\n",
       "      <td>56.0199890136717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N10002P</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.34599971771224</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>90.865997314449</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>26.3089904785155</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N10003Q</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.32099914550831</td>\n",
       "      <td>1.49899959564243</td>\n",
       "      <td>1.87999916076665</td>\n",
       "      <td>87.9599914550983</td>\n",
       "      <td>96.4049987792867</td>\n",
       "      <td>89.382995605487</td>\n",
       "      <td>24.4939880371087</td>\n",
       "      <td>38.1019897460905</td>\n",
       "      <td>66.6799926757659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10004R</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.29499912262003</td>\n",
       "      <td>1.51099967956562</td>\n",
       "      <td>1.62999916076665</td>\n",
       "      <td>105.16198730471</td>\n",
       "      <td>111.588989257796</td>\n",
       "      <td>132.054992675766</td>\n",
       "      <td>28.122985839843</td>\n",
       "      <td>45.8139953613169</td>\n",
       "      <td>72.7999877929584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10005S</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.34599971771224</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>129.382995605487</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>37.6489868164152</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1765 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ncdsid n622 n0region n1region n2region n3region n553 n545 n520 n490  \\\n",
       "0  N10001N    2        9        9        9        9   23    4    2   12   \n",
       "1  N10002P    1        9        8        8        8   34    4    5    1   \n",
       "2  N10003Q    1        4        4        4        4   34    4   10    1   \n",
       "3  N10004R    2        1        1        1        1   26    4   11    1   \n",
       "4  N10005S    2       10       10       10       10   25    4    1    3   \n",
       "\n",
       "         ...        n1849            dvht07            dvht11  \\\n",
       "0        ...           -1  1.21899986267032  1.47299957275415   \n",
       "1        ...           -1  1.34599971771224                -1   \n",
       "2        ...           -1  1.32099914550831  1.49899959564243   \n",
       "3        ...           -1  1.29499912262003  1.51099967956562   \n",
       "4        ...           -1  1.34599971771224                -1   \n",
       "\n",
       "             dvht16           dvrwt07           dvrwt11           dvrwt16  \\\n",
       "0  1.59999942779607  110.347991943347  98.1929931640604  105.055999755876   \n",
       "1                -1   90.865997314449                -1                -1   \n",
       "2  1.87999916076665  87.9599914550983  96.4049987792867   89.382995605487   \n",
       "3  1.62999916076665   105.16198730471  111.588989257796  132.054992675766   \n",
       "4                -1  129.382995605487                -1                -1   \n",
       "\n",
       "             dvwt07            dvwt11            dvwt16  \n",
       "0  25.8549957275385  37.6489868164152  56.0199890136717  \n",
       "1  26.3089904785155                -1                -1  \n",
       "2  24.4939880371087  38.1019897460905  66.6799926757659  \n",
       "3   28.122985839843  45.8139953613169  72.7999877929584  \n",
       "4  37.6489868164152                -1                -1  \n",
       "\n",
       "[5 rows x 1765 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and inspect the ncds data\n",
    "ncds_data = pd.read_csv('datasets/ncds0123.txt', delimiter='\\t', low_memory=False)\n",
    "# Print shapes\n",
    "print \"Shape of data:\", ncds_data.shape\n",
    "ncds_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (16990, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCDSID</th>\n",
       "      <th>N622</th>\n",
       "      <th>BSTATUS</th>\n",
       "      <th>POD</th>\n",
       "      <th>BOOKING</th>\n",
       "      <th>PLANC</th>\n",
       "      <th>DIASTOL</th>\n",
       "      <th>MAXDBP</th>\n",
       "      <th>ALBECL</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>...</th>\n",
       "      <th>DTB8</th>\n",
       "      <th>DTB9</th>\n",
       "      <th>DTB10</th>\n",
       "      <th>ILLNESS</th>\n",
       "      <th>MOD</th>\n",
       "      <th>TOD</th>\n",
       "      <th>AAD</th>\n",
       "      <th>SBNND</th>\n",
       "      <th>PLCWGT</th>\n",
       "      <th>TABLE62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10001N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N10002P</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N10003Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10004R</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10005S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NCDSID  N622  BSTATUS POD BOOKING PLANC DIASTOL MAXDBP ALBECL XRAY  \\\n",
       "0  N10001N     2        0   8       8     2       1      1      0    0   \n",
       "1  N10002P     1        0   2       0     4       4      3      0    0   \n",
       "2  N10003Q     1        0   8       8     2       1      3      0    0   \n",
       "3  N10004R     2        0   8       8     2       1     -8     -8    1   \n",
       "4  N10005S     2        0   8       8     2       1      3      0    1   \n",
       "\n",
       "    ...   DTB8 DTB9 DTB10 ILLNESS MOD TOD AAD SBNND PLCWGT TABLE62  \n",
       "0   ...      0    0     0       0   0  -1  -1    -1     -2      -1  \n",
       "1   ...      0    0     0       0   0  -1  -1    -1     -2      -1  \n",
       "2   ...      0    0     1       3   0  -1  -1    -1     -2      -1  \n",
       "3   ...      1    0     0      -1   0  -1  -1    -1     -2      -1  \n",
       "4   ...      0    0     0       0   0  -1  -1    -1     -2      -1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and inspect the pms additions data\n",
    "ncds_pms_data = pd.read_csv('datasets/ncds_pms_additionals.txt', delimiter='\\t', low_memory=False)\n",
    "# Print shapes\n",
    "print \"Shape of data:\", ncds_pms_data.shape\n",
    "ncds_pms_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (18558, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCDSID</th>\n",
       "      <th>N622</th>\n",
       "      <th>BSTATUS</th>\n",
       "      <th>COBIRTH</th>\n",
       "      <th>MULTIPNO</th>\n",
       "      <th>MULTCODE</th>\n",
       "      <th>ETHNICID</th>\n",
       "      <th>OUTCME00</th>\n",
       "      <th>OUTCME01</th>\n",
       "      <th>OUTCME02</th>\n",
       "      <th>OUTCME03</th>\n",
       "      <th>OUTCME04</th>\n",
       "      <th>OUTCME05</th>\n",
       "      <th>OUTCME06</th>\n",
       "      <th>OUTCMEBM</th>\n",
       "      <th>OUTCME07</th>\n",
       "      <th>OUTCME08</th>\n",
       "      <th>OUTCME09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10001N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N10002P</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N10003Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10004R</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10005S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NCDSID  N622  BSTATUS  COBIRTH  MULTIPNO  MULTCODE  ETHNICID  OUTCME00  \\\n",
       "0  N10001N     2        0        1        -1        -1         1         1   \n",
       "1  N10002P     1        0        1        -1        -1         1         1   \n",
       "2  N10003Q     1        0        1        -1        -1         1         1   \n",
       "3  N10004R     2        0        1        -1        -1         1         1   \n",
       "4  N10005S     2        0        2        -1        -1         5         1   \n",
       "\n",
       "   OUTCME01  OUTCME02  OUTCME03  OUTCME04  OUTCME05  OUTCME06  OUTCMEBM  \\\n",
       "0         1         1         1         1         1         1         1   \n",
       "1         1         1         1         1         1         1         1   \n",
       "2         1         1         1         7         7         7         6   \n",
       "3         1         1         1         1         1         1         1   \n",
       "4         1         1         1         2         2         2         6   \n",
       "\n",
       "   OUTCME07  OUTCME08  OUTCME09  \n",
       "0         1         1         1  \n",
       "1         1         1         1  \n",
       "2         7         7         7  \n",
       "3         2         2         3  \n",
       "4         6         6         6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and inspect the response data\n",
    "ncds_response_data = pd.read_csv('datasets/ncds_response.txt', delimiter='\\t', low_memory=False)\n",
    "# Print shapes\n",
    "print \"Shape of data:\", ncds_response_data.shape\n",
    "ncds_response_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1: Understand the data:\n",
    "\n",
    "1. Explore the data\n",
    "2. Understand the predictors, what they mean in real life\n",
    "3. Understand the values of each predictors\n",
    "4. Join appropriate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns the help us identify if the patient has epilepsy\n",
    "epil_columns = [\"n390\",\"n391\",\"n392\",\"n415\", \"n1842\", \"n1307\", \"n1308\", \"n1309\", \"n1314\", \"n1317\", \"n1477\", \"n1478\", \"n1479\", \"n2416\", \"n2663\", \"n2664\", \"n2665\"\n",
    "                , \"n2666\", \"n2667\", \"n1893\", \"n1894\", \"n1895\", \"n1904\", \"n1910\", \"n1817\", \"n1818\",\"n1819\",\"n1394\", \"n1502\", \"n2615\", \"n2616\"]\n",
    "\n",
    "def evaluate_data(df):\n",
    "    # Check for range of unique values for the train data\n",
    "    for i in range(df.shape[1]):\n",
    "        vals = np.unique(df.iloc[:, i])\n",
    "        if len(vals) < 15:\n",
    "            print '(Categorical) {} unique values - {}: {}'.format(len(vals), df.columns[i], vals)\n",
    "        else:\n",
    "            print '(Continuous) range of values - ', df.columns[i], ': {} to {}'.format(df.iloc[:, i].min(), df.iloc[:, i].max())\n",
    "\n",
    "def evaluate_epil_columns(df):\n",
    "    for column in epil_columns:\n",
    "        vals = np.unique(df[column])\n",
    "        if len(vals) < 15:\n",
    "            print '(Categorical) {} unique values - {}: {}'.format(len(vals), column, vals)\n",
    "        else:\n",
    "            print '(Continuous) range of values - ', column, ': {} to {}'.format(df[column].min(), df[column].max())\n",
    "\n",
    "\n",
    "def columns_with_null(df):\n",
    "    for column in df.columns:\n",
    "        df_missing = df[df[column].isnull()]\n",
    "        count = 0\n",
    "        if df_missing.shape[0] > 0:\n",
    "            print \"Predictor \" , column, \" contain null values / Count = \" ,df_missing.shape[0]\n",
    "            count = count +1\n",
    "    print \"Total number of columns with null:\",count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (18558, 1837)\n"
     ]
    }
   ],
   "source": [
    "# Join datasets\n",
    "ncds_merged_data = pd.merge(left=ncds_data,right=ncds_pms_data,how='left',left_on='ncdsid',right_on='NCDSID')\n",
    "ncds_merged_data = pd.merge(left=ncds_merged_data,right=ncds_response_data,how='left',left_on='ncdsid',right_on='NCDSID')\n",
    "print \"Shape of data:\", ncds_merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evalute the ncds data\n",
    "#evaluate_data(ncds_merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2: Handle missing data:\n",
    "\n",
    "Are there any missing values, if there are:\n",
    "1. Can we impute them based on some algorithm\n",
    "2. Remove or ignore them\n",
    "3. Assume values based on common sense or prior knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove spaces from data\n",
    "def convert_spaces_to_null(data):\n",
    "    data = data.replace([' '],[None]) \n",
    "    return data\n",
    "\n",
    "def fill_with_median(x_fill):\n",
    "    x_fill = x_fill.groupby(x_fill.columns, axis = 1).transform(lambda x: x.fillna(x.median()))\n",
    "    return x_fill\n",
    "\n",
    "def fill_with_mean(x_fill):\n",
    "    x_fill = x_fill.groupby(x_fill.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\n",
    "    return x_fill\n",
    "\n",
    "def fill_pms_columns(x_fill):\n",
    "    for index, row in x_fill.iterrows():\n",
    "#         # 0-3D Sex of child \n",
    "#         if pd.isnull(row[\"N622\"]):\n",
    "#             x_fill.set_value(index, 'N622', -1.0)\n",
    "        # Reconciled Birth Status  \n",
    "#         if pd.isnull(row[\"BSTATUS\"]):\n",
    "#             x_fill.set_value(index, 'BSTATUS', 0)\n",
    "        # Q6:Place of Delivery  \n",
    "        if pd.isnull(row[\"POD\"]):\n",
    "            x_fill.set_value(index, 'POD', 5.0)\n",
    "        # Q26b: Booking In place  \n",
    "        if pd.isnull(row[\"BOOKING\"]):\n",
    "            x_fill.set_value(index, 'BOOKING', 3.0)\n",
    "        # Q21b: Place of Antenatal care  \n",
    "        if pd.isnull(row[\"PLANC\"]):\n",
    "            x_fill.set_value(index, 'PLANC', -8.0)\n",
    "        # Q29a: Diastolic Blood Pressure  \n",
    "        if pd.isnull(row[\"DIASTOL\"]):\n",
    "            x_fill.set_value(index, 'DIASTOL', -2.0)\n",
    "        # Q29b: Maximum Diatolic Blood Pressure \n",
    "        if pd.isnull(row[\"MAXDBP\"]):\n",
    "            x_fill.set_value(index, 'MAXDBP', -2.0)\n",
    "        # Q31: Albuminuria and Eclampsia\n",
    "        if pd.isnull(row[\"ALBECL\"]):\n",
    "            x_fill.set_value(index, 'ALBECL', -8.0)\n",
    "        # Q36: X-Ray given\n",
    "        if pd.isnull(row[\"XRAY\"]):\n",
    "            x_fill.set_value(index, 'XRAY', -8.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - No information\n",
    "        if pd.isnull(row[\"ABNORM0X\"]):\n",
    "            x_fill.set_value(index, 'ABNORM0X', -2.0)\n",
    "        # Q37: No Obstetric, pregnancy abnormality\n",
    "        if pd.isnull(row[\"ABNORM00\"]):\n",
    "            x_fill.set_value(index, 'ABNORM00', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Diabetes\n",
    "        if pd.isnull(row[\"ABNORM01\"]):\n",
    "            x_fill.set_value(index, 'ABNORM01', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Heart \n",
    "        if pd.isnull(row[\"ABNORM02\"]):\n",
    "            x_fill.set_value(index, 'ABNORM02', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Active TB \n",
    "        if pd.isnull(row[\"ABNORM03\"]):\n",
    "            x_fill.set_value(index, 'ABNORM03', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - influenza \n",
    "        if pd.isnull(row[\"ABNORM04\"]):\n",
    "            x_fill.set_value(index, 'ABNORM04', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - German Measles \n",
    "        if pd.isnull(row[\"ABNORM05\"]):\n",
    "            x_fill.set_value(index, 'ABNORM05', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Disproportion \n",
    "        if pd.isnull(row[\"ABNORM06\"]):\n",
    "            x_fill.set_value(index, 'ABNORM06', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - External version \n",
    "        if pd.isnull(row[\"ABNORM07\"]):\n",
    "            x_fill.set_value(index, 'ABNORM07', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Epilepsy \n",
    "        if pd.isnull(row[\"ABNORM08\"]):\n",
    "            x_fill.set_value(index, 'ABNORM08', -2.0)\n",
    "        # Q37: Obstetric, pregnancy abnormality - Other \n",
    "        if pd.isnull(row[\"ABNORM09\"]):\n",
    "            x_fill.set_value(index, 'ABNORM09', -2.0)\n",
    "        # Q37: Bleeding in Pregnancy and before delivery \n",
    "        if pd.isnull(row[\"BLEED\"]):\n",
    "            x_fill.set_value(index, 'BLEED', -1.0)\n",
    "        # Q38a: Admission to hospital  \n",
    "        if pd.isnull(row[\"AD2HOSP\"]):\n",
    "            x_fill.set_value(index, 'AD2HOSP', -1.0)\n",
    "        # Q39: Type of Labour or Delivery Admission (Hospital)  \n",
    "        if pd.isnull(row[\"ADTYPE\"]):\n",
    "            x_fill.set_value(index, 'ADTYPE', -1.0)\n",
    "        # Q44: Presenting Part  \n",
    "        if pd.isnull(row[\"PRESENT\"]):\n",
    "            x_fill.set_value(index, 'PRESENT', -1.0)\n",
    "        # Q49a: No drugs of this type  \n",
    "        if pd.isnull(row[\"LDRUG00\"]):\n",
    "            x_fill.set_value(index, 'LDRUG00', -2.0)\n",
    "        # Q49a: Chloral, Welldorm  \n",
    "        if pd.isnull(row[\"LDRUG01\"]):\n",
    "            x_fill.set_value(index, 'LDRUG01', -2.0)\n",
    "        # Q49a: Barbiturate   \n",
    "        if pd.isnull(row[\"LDRUG02\"]):\n",
    "            x_fill.set_value(index, 'LDRUG02', -2.0)\n",
    "        # Q49a: Heroin   \n",
    "        if pd.isnull(row[\"LDRUG03\"]):\n",
    "            x_fill.set_value(index, 'LDRUG03', -2.0)\n",
    "        # Q49a: Largactil (chlorpomazine)   \n",
    "        if pd.isnull(row[\"LDRUG04\"]):\n",
    "            x_fill.set_value(index, 'LDRUG04', -2.0)\n",
    "        # Q49a: Sparine (promazine)    \n",
    "        if pd.isnull(row[\"LDRUG05\"]):\n",
    "            x_fill.set_value(index, 'LDRUG05', -2.0)\n",
    "        # Q49a: Phenergan (promethazine)    \n",
    "        if pd.isnull(row[\"LDRUG06\"]):\n",
    "            x_fill.set_value(index, 'LDRUG06', -2.0)\n",
    "        # Q49a: Doriden    \n",
    "        if pd.isnull(row[\"LDRUG07\"]):\n",
    "            x_fill.set_value(index, 'LDRUG07', -2.0)\n",
    "        # Q49a: Oblivon    \n",
    "        if pd.isnull(row[\"LDRUG08\"]):\n",
    "            x_fill.set_value(index, 'LDRUG08', -2.0)\n",
    "        # Q49a: Other    \n",
    "        if pd.isnull(row[\"LDRUG09\"]):\n",
    "            x_fill.set_value(index, 'LDRUG09', -2.0)\n",
    "        # Q50: Anaesthetic    \n",
    "        if pd.isnull(row[\"ATHETIC\"]):\n",
    "            x_fill.set_value(index, 'ATHETIC', -2.0)\n",
    "        # Q55: Resuscitation    \n",
    "        if pd.isnull(row[\"RESUS\"]):\n",
    "            x_fill.set_value(index, 'RESUS', -2.0)\n",
    "        # Q56: Drugs to baby (None)      \n",
    "        if pd.isnull(row[\"DTB1\"]):\n",
    "            x_fill.set_value(index, 'DTB1', -2.0)\n",
    "        # Q56: Drugs to baby (Coranine)       \n",
    "        if pd.isnull(row[\"DTB2\"]):\n",
    "            x_fill.set_value(index, 'DTB2', -2.0)\n",
    "        # Q56: Drugs to baby (Lobeline)       \n",
    "        if pd.isnull(row[\"DTB3\"]):\n",
    "            x_fill.set_value(index, 'DTB3', -2.0)\n",
    "        # Q56: Drugs to baby (Sedatives)       \n",
    "        if pd.isnull(row[\"DTB4\"]):\n",
    "            x_fill.set_value(index, 'DTB4', -2.0)\n",
    "        # Q56: Drugs to baby (Antagonists, nalorphine, levalorfan)       \n",
    "        if pd.isnull(row[\"DTB5\"]):\n",
    "            x_fill.set_value(index, 'DTB5', -2.0)\n",
    "        # Q56: Drugs to baby (Synkavit, Vikastab)      \n",
    "        if pd.isnull(row[\"DTB6\"]):\n",
    "            x_fill.set_value(index, 'DTB6', -2.0)\n",
    "        # Q56: Drugs to baby (Sulphonamides)      \n",
    "        if pd.isnull(row[\"DTB7\"]):\n",
    "            x_fill.set_value(index, 'DTB7', -2.0)\n",
    "        # Q56: Drugs to baby (Penicilin)      \n",
    "        if pd.isnull(row[\"DTB8\"]):\n",
    "            x_fill.set_value(index, 'DTB8', -2.0)\n",
    "        # Q56: Drugs to baby (Streptomycin)       \n",
    "        if pd.isnull(row[\"DTB9\"]):\n",
    "            x_fill.set_value(index, 'DTB9', -2.0)\n",
    "        # Q56: Drugs to baby (Other antibiotics)       \n",
    "        if pd.isnull(row[\"DTB10\"]):\n",
    "            x_fill.set_value(index, 'DTB10', -2.0)\n",
    "        # Q59: Baby's Illness       \n",
    "        if pd.isnull(row[\"ILLNESS\"]):\n",
    "            x_fill.set_value(index, 'ILLNESS', -1.0)\n",
    "        # Q61: Month of Death       \n",
    "        if pd.isnull(row[\"MOD\"]):\n",
    "            x_fill.set_value(index, 'MOD', 0.0)\n",
    "        # Q61: Time of death        \n",
    "        if pd.isnull(row[\"TOD\"]):\n",
    "            x_fill.set_value(index, 'TOD', -1.0)\n",
    "        # Q61: Age at Death        \n",
    "        if pd.isnull(row[\"AAD\"]):\n",
    "            x_fill.set_value(index, 'AAD', -1.0)\n",
    "        # Q61: Still Birth or Neo-natal Death (Dervied)         \n",
    "        if pd.isnull(row[\"SBNND\"]):\n",
    "            x_fill.set_value(index, 'SBNND', -1.0)\n",
    "        # Placental Weight         \n",
    "        if pd.isnull(row[\"PLCWGT\"]):\n",
    "            x_fill.set_value(index, 'PLCWGT', -2.0)\n",
    "        # Time of death for still births and neonatal deaths (Table 62)          \n",
    "        if pd.isnull(row[\"TABLE62\"]):\n",
    "            x_fill.set_value(index, 'TABLE62', -1.0)\n",
    "    return x_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "ncds_data_clean = ncds_merged_data.copy() \n",
    "\n",
    "# drop the ID columns\n",
    "ncds_data_clean =  ncds_data_clean.drop([\"ncdsid\",\"NCDSID_x\",\"NCDSID_y\"],axis=1)\n",
    "# Drop other duplicate columns\n",
    "ncds_data_clean =  ncds_data_clean.drop([\"N622_x\",\"BSTATUS_x\"],axis=1)\n",
    "\n",
    "\n",
    "# Convert spaces in the data to nulls\n",
    "ncds_data_clean = convert_spaces_to_null(ncds_data_clean)\n",
    "\n",
    "# Convert all columns to float\n",
    "for column in ncds_data_clean.columns:\n",
    "    ncds_data_clean[column] = ncds_data_clean[column].astype(float)\n",
    "\n",
    "# Impute missing data from joined columns using default values\n",
    "ncds_data_clean = fill_pms_columns(ncds_data_clean)\n",
    "\n",
    "# Impute missing data with median values\n",
    "ncds_data_clean = fill_with_median(ncds_data_clean)\n",
    "\n",
    "# Impute missing data with mean values - there are some columns we cannot impute with median\n",
    "ncds_data_clean = fill_with_mean(ncds_data_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns with null: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the columns which have null data\n",
    "columns_with_null(ncds_data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3: Identify Epilepsy Records:\n",
    "\n",
    "In our data a patient is assumed to be epileptic is one or more conditions are satisified in the dataset. We need to check all the conditions in the data and determine if the patient is epileptic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify if patient has epilepsy\n",
    "ncds_data_clean[\"epileptic\"] = 0\n",
    "for index, row in ncds_data_clean.iterrows():\n",
    "    # 1M Reason for Special Education MC1:3\n",
    "    if row[\"n390\"] == 10.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 1M Reason for Special Education MC2:3\n",
    "    if row[\"n391\"] == 10.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 1M Reason for Special Education MC2:3\n",
    "    if row[\"n392\"] == 10.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 1M Epileptic condition\n",
    "    if row[\"n415\"] >= 3.0 :\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 12D Epilepsy identification\n",
    "    if row[\"n1842\"] == 5.0 :\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Has child had epilepsy attacks-MC 1:3\n",
    "    if (row[\"n1307\"] >= 1.0 and row[\"n1307\"] <= 5.0):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Has child had epilepsy attacks-MC 2:3\n",
    "    if (row[\"n1308\"] >= 1.0 and row[\"n1308\"] <= 5.0):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Has child had epilepsy attacks-MC 3:3\n",
    "    if (row[\"n1309\"] >= 1.0 and row[\"n1309\"] <= 5.0):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Age at most recent epilepsy attack\n",
    "    if (row[\"n1314\"] >= 0.0):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Age at 1st epilepsy attack\n",
    "    if (row[\"n1317\"] >= 0.0):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2M Reason for special education - MC1:3\n",
    "    if row[\"n1477\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2M Reason for special education - MC2:3\n",
    "    if row[\"n1478\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2M Reason for special education - MC3:3\n",
    "    if row[\"n1479\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Type hcap for which will require help\n",
    "    if row[\"n2416\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Nature of child-s disability-MC 1:5\n",
    "    if row[\"n2663\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Nature of child-s disability-MC 2:5\n",
    "    if row[\"n2664\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Nature of child-s disability-MC 3:5\n",
    "    if row[\"n2665\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Nature of child-s disability-MC 4:5\n",
    "    if row[\"n2666\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Nature of child-s disability-MC 5:5\n",
    "    if row[\"n2667\"] == 7.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Category of child's handicap MC1:3\n",
    "    if row[\"n1893\"] == 8.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Category of child's handicap MC2:3\n",
    "    if row[\"n1894\"] == 8.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Category of child's handicap MC3:3\n",
    "    if row[\"n1895\"] == 8.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Reason for hosp admiss last 12 mnths\n",
    "    if row[\"n1904\"] == 17.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Reason hosp outpatient last yr\n",
    "    if row[\"n1910\"] == 17.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3M Epilepsy\n",
    "#     if row[\"n2032\"] >= 1.0:\n",
    "#         ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    \n",
    "    # New columns \n",
    "    \n",
    "    # 1D Defects found in NCDS1 sample-MC 1:4\n",
    "    if row[\"n1817\"] > 0.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 1D Defects found in NCDS1 sample-MC 2:4\n",
    "    if row[\"n1818\"] > 0.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 1D Defects found in NCDS1 sample-MC 3:4\n",
    "    if row[\"n1819\"] > 0.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2P Ever seen specialist-convulsions,fits\n",
    "    if row[\"n1394\"] == 5.0:\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 2M Has child ever had convulsions\n",
    "    if any(row[\"n1502\"] == s for s in [2.0,3.0,4.0]):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P When convulsions,fits 1st occured\n",
    "    if any(row[\"n2615\"] == s for s in [1.0,2.0,3.0,4.0,5.0,6.0]):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)\n",
    "    # 3P Convulsions-most recent occurrence\n",
    "    if any(row[\"n2616\"] == s for s in [1.0,2.0,3.0,4.0,5.0,6.0,7.0]):\n",
    "        ncds_data_clean.set_value(index, 'epileptic', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with epilepsy 1609\n"
     ]
    }
   ],
   "source": [
    "print \"Number of rows with epilepsy\",ncds_data_clean[ncds_data_clean[\"epileptic\"] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset:  (18558, 1802)\n"
     ]
    }
   ],
   "source": [
    "# Remove the epilepsy columns from the data\n",
    "ncds_data_no_indicators=ncds_data_clean.copy()\n",
    "ncds_data_no_indicators.drop(epil_columns,inplace=True,axis=1)\n",
    "print \"Shape of dataset: \" , ncds_data_no_indicators.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4: Split data into train and test:\n",
    "\n",
    "Split our dataset into train and test and analyze the splits. We can explore and verify the matrix of classes to check if our data is balanced. If the class is Imbalanced we will need to do any of the following:\n",
    "1. Over sample\n",
    "2. Under sample\n",
    "3. Over weight\n",
    "4. Adjust class weights in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (11134, 1801)\n",
      "Test data:  (7424, 1801)\n",
      "Train class 0: 10159, train class 1: 975\n",
      "Test class 0: 6790, test class 1: 634\n"
     ]
    }
   ],
   "source": [
    "x = ncds_data_no_indicators.values[:, :-1]\n",
    "y = ncds_data_no_indicators.values[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#Print some useful info for our test, train sets\n",
    "print 'Train data: ', x_train.shape\n",
    "print 'Test data: ', x_test.shape\n",
    "print 'Train class 0: {}, train class 1: {}'.format(len(y_train[y_train == 0]), len(y_train[y_train == 1]))\n",
    "print 'Test class 0: {}, test class 1: {}'.format(len(y_test[y_test == 0]), len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Selection\n",
    "\n",
    "From the merged datasets we can see we have over 1800 features. Going through the 1800 would be a very time consuming task so let us apply some algorithims to find the best features that we can use to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['n1827' 'n604' 'n39' 'n1263' 'n1400' 'n1399' 'n1453' 'n1476' 'n825'\n",
      " 'n2598' 'n1896' 'n1898' 'dvht07' 'OUTCME01' 'OUTCME02']\n"
     ]
    }
   ],
   "source": [
    "# Best features\n",
    "num_of_features = 15\n",
    "features = fs.SelectKBest(fs.f_regression, k=num_of_features) #k is number of features.\n",
    "features.fit(x_train, y_train)\n",
    "\n",
    "selected_features = features.get_support()\n",
    "print \"Selected Features:\"\n",
    "print ncds_data_no_indicators.columns[selected_features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for computing the accuracy a given model on the entire test set,\n",
    "# the accuracy on class 0 in the test set\n",
    "# and the accuracy on class 1\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (11134, 15)\n",
      "Test data:  (7424, 15)\n",
      "Train class 0: 10159, train class 1: 975\n",
      "Test class 0: 6790, test class 1: 634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:2: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 1; dimension is 1802 but corresponding boolean dimension is 1801\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Split data for selected features only\n",
    "x = ncds_data_no_indicators.values[:, selected_features]\n",
    "y = ncds_data_no_indicators.values[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#Print some useful info for our test, train sets\n",
    "print 'Train data: ', x_train.shape\n",
    "print 'Test data: ', x_test.shape\n",
    "print 'Train class 0: {}, train class 1: {}'.format(len(y_train[y_train == 0]), len(y_train[y_train == 1]))\n",
    "print 'Test class 0: {}, test class 1: {}'.format(len(y_test[y_test == 0]), len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:\n",
      "overall accuracy       0.050431\n",
      "accuracy on class 0    0.000000\n",
      "accuracy on class 1    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train, y_train)\n",
    "linear_scores = score(linear, x_test, y_test)\n",
    "print \"Linear regression:\"\n",
    "print linear_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.2: Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (Unweighted):\n",
      "overall accuracy       0.915948\n",
      "accuracy on class 0    0.997791\n",
      "accuracy on class 1    0.039432\n",
      "dtype: float64\n",
      "Logistic regression (Weighted):\n",
      "overall accuracy       0.623788\n",
      "accuracy on class 0    0.625626\n",
      "accuracy on class 1    0.604101\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train)\n",
    "unweighted_log_scores = score(unweighted_logistic, x_test, y_test)\n",
    "\n",
    "# Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train)\n",
    "weighted_log_scores = score(weighted_logistic, x_test, y_test)\n",
    "\n",
    "print \"Logistic regression (Unweighted):\"\n",
    "print unweighted_log_scores\n",
    "print \"Logistic regression (Weighted):\"\n",
    "print weighted_log_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.3: Linear Discriminant Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:\n",
      "overall accuracy       0.912177\n",
      "accuracy on class 0    0.988954\n",
      "accuracy on class 1    0.089905\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_scores = score(lda, x_test, y_test)\n",
    "\n",
    "print \"LDA:\"\n",
    "print lda_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's group the data by demographics and perform a feature selection on each individual group\n",
    "1. Sex\n",
    "2. Country of birth\n",
    "3. Ethnic group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "### Find factors effecting seizures across different sex\n",
    "list_of_sex = list(ncds_data_no_indicators['n622'].unique())\n",
    "print list_of_sex\n",
    "\n",
    "#for i in list_of_sex:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 9.0, 3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "### Find factors effecting seizures based on country of birth\n",
    "list_of_cob = list(ncds_data_no_indicators['COBIRTH'].unique())\n",
    "print list_of_cob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 5.0, 6.0, 3.0, 2.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "### Find factors effecting seizures based on ethinic group\n",
    "list_of_eg = list(ncds_data_no_indicators['ETHNICID'].unique())\n",
    "print list_of_eg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.4: Other Models:\n",
    "\n",
    "Let us build some more baseline models using other techniques and compare to the ones above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>lda</th>\n",
       "      <th>linear</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>svc</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.909752</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.851832</td>\n",
       "      <td>0.796740</td>\n",
       "      <td>0.715383</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.915948</td>\n",
       "      <td>0.623788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.988218</td>\n",
       "      <td>0.988954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.911487</td>\n",
       "      <td>0.854050</td>\n",
       "      <td>0.737113</td>\n",
       "      <td>0.965685</td>\n",
       "      <td>0.997791</td>\n",
       "      <td>0.625626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.069401</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212934</td>\n",
       "      <td>0.182965</td>\n",
       "      <td>0.482650</td>\n",
       "      <td>0.146688</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.604101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          knn       lda    linear       qda        rf  \\\n",
       "overall accuracy     0.909752  0.912177  0.050431  0.851832  0.796740   \n",
       "accuracy on class 0  0.988218  0.988954  0.000000  0.911487  0.854050   \n",
       "accuracy on class 1  0.069401  0.089905  0.000000  0.212934  0.182965   \n",
       "\n",
       "                          svc      tree  unweighted logistic  \\\n",
       "overall accuracy     0.715383  0.895744             0.915948   \n",
       "accuracy on class 0  0.737113  0.965685             0.997791   \n",
       "accuracy on class 1  0.482650  0.146688             0.039432   \n",
       "\n",
       "                     weighted logistic  \n",
       "overall accuracy              0.623788  \n",
       "accuracy on class 0           0.625626  \n",
       "accuracy on class 1           0.604101  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNN()\n",
    "knn.fit(x_train, y_train)\n",
    "knn_scores = score(knn, x_test, y_test)\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train)\n",
    "qda_scores = score(qda, x_test, y_test)\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree()\n",
    "tree.fit(x_train, y_train)\n",
    "tree_scores = score(tree, x_test, y_test)\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForest(class_weight='balanced')\n",
    "rf.fit(x_train, y_train)\n",
    "rf_scores = score(rf, x_test, y_test)\n",
    "\n",
    "# SVC\n",
    "svc = SVC(probability=True,class_weight='balanced')\n",
    "svc.fit(x_train, y_train)\n",
    "svc_scores = score(svc, x_test, y_test)\n",
    "\n",
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'linear':linear_scores,\n",
    "                         'unweighted logistic': unweighted_log_scores,\n",
    "                         'weighted logistic': weighted_log_scores,\n",
    "                         'lda': lda_scores,\n",
    "                         'qda': qda_scores,\n",
    "                        'knn': knn_scores,\n",
    "                         'tree': tree_scores,\n",
    "                         'rf': rf_scores,'svc':svc_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
